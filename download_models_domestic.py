#!/usr/bin/env python3
"""
ä½¿ç”¨å›½å†…é•œåƒä¸‹è½½å¤§æ¨¡å‹è„šæœ¬
"""

import os
import sys
import time
import subprocess
from pathlib import Path
import requests
from huggingface_hub import snapshot_download, hf_hub_download
from modelscope import snapshot_download as ms_snapshot_download
from modelscope.hub.file_download import model_file_download
import torch

def setup_domestic_mirrors():
    """é…ç½®å›½å†…é•œåƒæº"""
    print("=== é…ç½®å›½å†…é•œåƒæº ===")
    
    # è®¾ç½®Hugging Faceé•œåƒ
    os.environ['HF_ENDPOINT'] = 'https://hf-mirror.com'
    
    # è®¾ç½®pipé•œåƒ
    pip_config_commands = [
        "pip config set global.index-url https://pypi.tuna.tsinghua.edu.cn/simple",
        "pip config set install.trusted-host pypi.tuna.tsinghua.edu.cn"
    ]
    
    for cmd in pip_config_commands:
        try:
            result = subprocess.run(cmd.split(), capture_output=True, text=True)
            if result.returncode == 0:
                print(f"âœ“ {cmd}")
            else:
                print(f"âœ— {cmd}: {result.stderr}")
        except Exception as e:
            print(f"âœ— {cmd}: {e}")
    
    print("é•œåƒæºé…ç½®å®Œæˆ\n")

def download_clip_models():
    """ä¸‹è½½CLIPæ¨¡å‹"""
    print("=== ä¸‹è½½CLIPæ¨¡å‹ ===")
    
    clip_models = {
        "CLIP ViT-B/32": "openai/clip-vit-base-patch32",
        "CLIP ViT-B/16": "openai/clip-vit-base-patch16", 
        "CLIP ViT-L/14": "openai/clip-vit-large-patch14"
    }
    
    cache_dir = "./data/cache/models/clip"
    os.makedirs(cache_dir, exist_ok=True)
    
    for model_name, model_id in clip_models.items():
        print(f"\nä¸‹è½½ {model_name} ({model_id})...")
        
        try:
            # æ–¹æ³•1: å°è¯•ä½¿ç”¨é­”æ­ç¤¾åŒº
            print(f"  å°è¯•ä»é­”æ­ç¤¾åŒºä¸‹è½½...")
            start_time = time.time()
            
            # é­”æ­ç¤¾åŒºçš„æ¨¡å‹IDæ˜ å°„
            ms_model_mapping = {
                "openai/clip-vit-base-patch32": "AI-ModelScope/clip-vit-base-patch32",
                "openai/clip-vit-base-patch16": "AI-ModelScope/clip-vit-base-patch16",
                "openai/clip-vit-large-patch14": "AI-ModelScope/clip-vit-large-patch14"
            }
            
            if model_id in ms_model_mapping:
                ms_model_id = ms_model_mapping[model_id]
                model_dir = ms_snapshot_download(
                    ms_model_id,
                    cache_dir=cache_dir,
                    revision='master'
                )
                end_time = time.time()
                download_time = end_time - start_time
                print(f"  âœ“ é­”æ­ç¤¾åŒºä¸‹è½½æˆåŠŸ: {model_dir}")
                print(f"  ä¸‹è½½æ—¶é—´: {download_time:.2f} ç§’")
                continue
                
        except Exception as e:
            print(f"  âœ— é­”æ­ç¤¾åŒºä¸‹è½½å¤±è´¥: {e}")
        
        try:
            # æ–¹æ³•2: ä½¿ç”¨HFé•œåƒ
            print(f"  å°è¯•ä»HFé•œåƒä¸‹è½½...")
            start_time = time.time()
            
            model_dir = snapshot_download(
                model_id,
                cache_dir=cache_dir,
                resume_download=True,
                local_files_only=False
            )
            
            end_time = time.time()
            download_time = end_time - start_time
            print(f"  âœ“ HFé•œåƒä¸‹è½½æˆåŠŸ: {model_dir}")
            print(f"  ä¸‹è½½æ—¶é—´: {download_time:.2f} ç§’")
            
        except Exception as e:
            print(f"  âœ— HFé•œåƒä¸‹è½½å¤±è´¥: {e}")
            
        try:
            # æ–¹æ³•3: ç›´æ¥ä½¿ç”¨transformersåŠ è½½ï¼ˆä¼šè‡ªåŠ¨ä¸‹è½½ï¼‰
            print(f"  å°è¯•ä½¿ç”¨transformersè‡ªåŠ¨ä¸‹è½½...")
            start_time = time.time()
            
            from transformers import CLIPModel, CLIPProcessor
            
            model = CLIPModel.from_pretrained(
                model_id,
                cache_dir=cache_dir,
                resume_download=True
            )
            processor = CLIPProcessor.from_pretrained(
                model_id,
                cache_dir=cache_dir,
                resume_download=True
            )
            
            end_time = time.time()
            download_time = end_time - start_time
            print(f"  âœ“ transformersè‡ªåŠ¨ä¸‹è½½æˆåŠŸ")
            print(f"  ä¸‹è½½æ—¶é—´: {download_time:.2f} ç§’")
            
            # æ¸…ç†å†…å­˜
            del model, processor
            torch.cuda.empty_cache()
            
        except Exception as e:
            print(f"  âœ— transformersè‡ªåŠ¨ä¸‹è½½å¤±è´¥: {e}")
            print(f"  {model_name} ä¸‹è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥")

def download_stable_diffusion_models():
    """ä¸‹è½½Stable Diffusionæ¨¡å‹"""
    print("\n=== ä¸‹è½½Stable Diffusionæ¨¡å‹ ===")
    
    sd_models = {
        "Stable Diffusion v1.5": "runwayml/stable-diffusion-v1-5"
    }
    
    cache_dir = "./data/cache/models/stable_diffusion"
    os.makedirs(cache_dir, exist_ok=True)
    
    for model_name, model_id in sd_models.items():
        print(f"\nä¸‹è½½ {model_name} ({model_id})...")
        
        try:
            # æ–¹æ³•1: å°è¯•ä½¿ç”¨é­”æ­ç¤¾åŒº
            print(f"  å°è¯•ä»é­”æ­ç¤¾åŒºä¸‹è½½...")
            start_time = time.time()
            
            # é­”æ­ç¤¾åŒºçš„SDæ¨¡å‹ID
            ms_model_mapping = {
                "runwayml/stable-diffusion-v1-5": "AI-ModelScope/stable-diffusion-v1-5"
            }
            
            if model_id in ms_model_mapping:
                ms_model_id = ms_model_mapping[model_id]
                model_dir = ms_snapshot_download(
                    ms_model_id,
                    cache_dir=cache_dir,
                    revision='master'
                )
                end_time = time.time()
                download_time = end_time - start_time
                print(f"  âœ“ é­”æ­ç¤¾åŒºä¸‹è½½æˆåŠŸ: {model_dir}")
                print(f"  ä¸‹è½½æ—¶é—´: {download_time:.2f} ç§’ ({download_time/60:.2f} åˆ†é’Ÿ)")
                continue
                
        except Exception as e:
            print(f"  âœ— é­”æ­ç¤¾åŒºä¸‹è½½å¤±è´¥: {e}")
        
        try:
            # æ–¹æ³•2: ä½¿ç”¨diffusersåº“ä¸‹è½½
            print(f"  å°è¯•ä½¿ç”¨diffusersä¸‹è½½...")
            start_time = time.time()
            
            from diffusers import StableDiffusionPipeline
            
            pipeline = StableDiffusionPipeline.from_pretrained(
                model_id,
                cache_dir=cache_dir,
                resume_download=True,
                torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32
            )
            
            end_time = time.time()
            download_time = end_time - start_time
            print(f"  âœ“ diffusersä¸‹è½½æˆåŠŸ")
            print(f"  ä¸‹è½½æ—¶é—´: {download_time:.2f} ç§’ ({download_time/60:.2f} åˆ†é’Ÿ)")
            
            # æ¸…ç†å†…å­˜
            del pipeline
            torch.cuda.empty_cache()
            
        except Exception as e:
            print(f"  âœ— diffusersä¸‹è½½å¤±è´¥: {e}")
        
        try:
            # æ–¹æ³•3: ä½¿ç”¨HFé•œåƒ
            print(f"  å°è¯•ä»HFé•œåƒä¸‹è½½...")
            start_time = time.time()
            
            model_dir = snapshot_download(
                model_id,
                cache_dir=cache_dir,
                resume_download=True,
                local_files_only=False
            )
            
            end_time = time.time()
            download_time = end_time - start_time
            print(f"  âœ“ HFé•œåƒä¸‹è½½æˆåŠŸ: {model_dir}")
            print(f"  ä¸‹è½½æ—¶é—´: {download_time:.2f} ç§’ ({download_time/60:.2f} åˆ†é’Ÿ)")
            
        except Exception as e:
            print(f"  âœ— HFé•œåƒä¸‹è½½å¤±è´¥: {e}")
            print(f"  {model_name} ä¸‹è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥")

def check_downloaded_models():
    """æ£€æŸ¥å·²ä¸‹è½½çš„æ¨¡å‹"""
    print("\n=== æ£€æŸ¥å·²ä¸‹è½½æ¨¡å‹ ===")
    
    cache_dirs = [
        "./data/cache/models/clip",
        "./data/cache/models/stable_diffusion",
        os.path.expanduser("~/.cache/huggingface"),
        os.path.expanduser("~/.cache/modelscope")
    ]
    
    total_size = 0
    
    for cache_dir in cache_dirs:
        if os.path.exists(cache_dir):
            try:
                result = subprocess.run(
                    ["du", "-sh", cache_dir], 
                    capture_output=True, 
                    text=True, 
                    timeout=30
                )
                if result.returncode == 0:
                    size_str = result.stdout.split()[0]
                    print(f"âœ“ {cache_dir}: {size_str}")
                    
                    # å°è¯•è§£æå¤§å°
                    try:
                        if 'G' in size_str:
                            size_gb = float(size_str.replace('G', ''))
                            total_size += size_gb
                        elif 'M' in size_str:
                            size_mb = float(size_str.replace('M', ''))
                            total_size += size_mb / 1024
                    except:
                        pass
                else:
                    print(f"? {cache_dir}: æ— æ³•è®¡ç®—å¤§å°")
            except Exception as e:
                print(f"? {cache_dir}: æ£€æŸ¥å¤±è´¥ - {e}")
        else:
            print(f"âœ— {cache_dir}: ä¸å­˜åœ¨")
    
    if total_size > 0:
        print(f"\næ€»ç¼“å­˜å¤§å°çº¦: {total_size:.2f} GB")

def test_model_loading():
    """æµ‹è¯•æ¨¡å‹åŠ è½½"""
    print("\n=== æµ‹è¯•æ¨¡å‹åŠ è½½ ===")
    
    # æµ‹è¯•CLIPæ¨¡å‹åŠ è½½
    try:
        print("æµ‹è¯•CLIPæ¨¡å‹åŠ è½½...")
        from transformers import CLIPModel, CLIPProcessor
        
        model_id = "openai/clip-vit-base-patch32"
        start_time = time.time()
        
        model = CLIPModel.from_pretrained(model_id)
        processor = CLIPProcessor.from_pretrained(model_id)
        
        end_time = time.time()
        load_time = end_time - start_time
        
        print(f"âœ“ CLIPæ¨¡å‹åŠ è½½æˆåŠŸ (è€—æ—¶: {load_time:.2f} ç§’)")
        
        # æ¸…ç†å†…å­˜
        del model, processor
        torch.cuda.empty_cache()
        
    except Exception as e:
        print(f"âœ— CLIPæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
    
    # æµ‹è¯•Stable Diffusionæ¨¡å‹åŠ è½½
    try:
        print("æµ‹è¯•Stable Diffusionæ¨¡å‹åŠ è½½...")
        from diffusers import StableDiffusionPipeline
        
        model_id = "runwayml/stable-diffusion-v1-5"
        start_time = time.time()
        
        pipeline = StableDiffusionPipeline.from_pretrained(
            model_id,
            torch_dtype=torch.float16 if torch.cuda.is_available() else torch.float32
        )
        
        if torch.cuda.is_available():
            pipeline = pipeline.to("cuda")
        
        end_time = time.time()
        load_time = end_time - start_time
        
        print(f"âœ“ Stable Diffusionæ¨¡å‹åŠ è½½æˆåŠŸ (è€—æ—¶: {load_time:.2f} ç§’)")
        
        # æ¸…ç†å†…å­˜
        del pipeline
        torch.cuda.empty_cache()
        
    except Exception as e:
        print(f"âœ— Stable Diffusionæ¨¡å‹åŠ è½½å¤±è´¥: {e}")

def install_required_packages():
    """å®‰è£…å¿…è¦çš„åŒ…"""
    print("=== å®‰è£…å¿…è¦çš„åŒ… ===")
    
    packages = [
        "modelscope",
        "huggingface_hub",
        "transformers",
        "diffusers",
        "accelerate"
    ]
    
    for package in packages:
        try:
            print(f"å®‰è£… {package}...")
            result = subprocess.run(
                [sys.executable, "-m", "pip", "install", package, "--upgrade"],
                capture_output=True,
                text=True,
                timeout=300
            )
            
            if result.returncode == 0:
                print(f"âœ“ {package} å®‰è£…æˆåŠŸ")
            else:
                print(f"âœ— {package} å®‰è£…å¤±è´¥: {result.stderr}")
                
        except Exception as e:
            print(f"âœ— {package} å®‰è£…å¼‚å¸¸: {e}")

def main():
    """ä¸»å‡½æ•°"""
    print("ä½¿ç”¨å›½å†…é•œåƒä¸‹è½½å¤§æ¨¡å‹")
    print("=" * 50)
    
    # 1. å®‰è£…å¿…è¦çš„åŒ…
    install_required_packages()
    
    # 2. é…ç½®å›½å†…é•œåƒæº
    setup_domestic_mirrors()
    
    # 3. ä¸‹è½½CLIPæ¨¡å‹
    download_clip_models()
    
    # 4. ä¸‹è½½Stable Diffusionæ¨¡å‹
    download_stable_diffusion_models()
    
    # 5. æ£€æŸ¥å·²ä¸‹è½½çš„æ¨¡å‹
    check_downloaded_models()
    
    # 6. æµ‹è¯•æ¨¡å‹åŠ è½½
    test_model_loading()
    
    print("\n=== ä¸‹è½½å®Œæˆ ===")
    print("ğŸ’¡ æç¤º:")
    print("1. æ¨¡å‹å·²ä¸‹è½½åˆ°æœ¬åœ°ç¼“å­˜ï¼Œåç»­ä½¿ç”¨ä¼šç›´æ¥ä»ç¼“å­˜åŠ è½½")
    print("2. å¦‚æœæŸäº›æ¨¡å‹ä¸‹è½½å¤±è´¥ï¼Œå¯ä»¥å•ç‹¬é‡è¯•")
    print("3. å»ºè®®å®šæœŸæ¸…ç†ä¸éœ€è¦çš„æ¨¡å‹ç¼“å­˜ä»¥èŠ‚çœç£ç›˜ç©ºé—´")
    print("4. å¯ä»¥ä½¿ç”¨ 'huggingface-cli scan-cache' æŸ¥çœ‹ç¼“å­˜è¯¦æƒ…")

if __name__ == "__main__":
    main()