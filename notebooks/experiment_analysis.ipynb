{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多模态检测一致性实验 - 实验分析\n",
    "\n",
    "本notebook用于深入分析实验结果，包括性能评估、对比分析和可视化展示。\n",
    "\n",
    "## 目录\n",
    "1. [环境设置](#环境设置)\n",
    "2. [数据加载](#数据加载)\n",
    "3. [基准测试](#基准测试)\n",
    "4. [性能评估](#性能评估)\n",
    "5. [对比分析](#对比分析)\n",
    "6. [错误分析](#错误分析)\n",
    "7. [参数敏感性分析](#参数敏感性分析)\n",
    "8. [可视化报告](#可视化报告)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 环境设置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 添加项目路径\n",
    "sys.path.append('../src')\n",
    "\n",
    "# 导入必要的库\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import yaml\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "# 导入项目模块\n",
    "from src.evaluation.experiment_evaluator import ExperimentEvaluator, ExperimentConfig\n",
    "from src.utils.metrics import RetrievalEvaluator, DetectionEvaluator\n",
    "from src.utils.visualizer import ResultVisualizer, VisualizationConfig\n",
    "from src.pipeline import DefensePipeline, PipelineConfig\n",
    "\n",
    "# 设置绘图样式\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"实验分析环境设置完成！\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载实验配置\n",
    "with open('../configs/default.yaml', 'r', encoding='utf-8') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "# 设置实验路径\n",
    "experiment_dir = Path('../experiments')\n",
    "results_dir = Path('../results')\n",
    "\n",
    "# 加载实验结果（如果存在）\n",
    "experiment_results = []\n",
    "\n",
    "if results_dir.exists():\n",
    "    for result_file in results_dir.glob('*.pkl'):\n",
    "        try:\n",
    "            with open(result_file, 'rb') as f:\n",
    "                result = pickle.load(f)\n",
    "                experiment_results.append(result)\n",
    "                print(f\"加载实验结果: {result_file.name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"加载 {result_file.name} 失败: {e}\")\n",
    "\n",
    "print(f\"\\n总共加载了 {len(experiment_results)} 个实验结果\")\n",
    "\n",
    "# 如果没有现有结果，创建模拟数据\n",
    "if not experiment_results:\n",
    "    print(\"\\n没有找到现有实验结果，将创建模拟数据进行演示...\")\n",
    "    \n",
    "    # 创建模拟实验数据\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    # 模拟不同方法的性能数据\n",
    "    methods = ['Baseline', 'Text-Variant', 'SD-Reference', 'Full-Pipeline']\n",
    "    metrics = ['accuracy', 'precision', 'recall', 'f1_score', 'auc_roc']\n",
    "    \n",
    "    simulation_data = {}\n",
    "    for method in methods:\n",
    "        simulation_data[method] = {}\n",
    "        base_performance = 0.7 + np.random.random() * 0.2\n",
    "        for metric in metrics:\n",
    "            # 添加一些随机变化\n",
    "            noise = np.random.normal(0, 0.05)\n",
    "            simulation_data[method][metric] = np.clip(base_performance + noise, 0, 1)\n",
    "    \n",
    "    print(\"模拟数据创建完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 基准测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化评估器\n",
    "experiment_config = ExperimentConfig(\n",
    "    experiment_name=\"benchmark_analysis\",\n",
    "    metrics=['accuracy', 'precision', 'recall', 'f1_score', 'auc_roc'],\n",
    "    enable_cross_validation=True,\n",
    "    cv_folds=5,\n",
    "    enable_statistical_tests=True,\n",
    "    enable_visualization=True\n",
    ")\n",
    "\n",
    "evaluator = ExperimentEvaluator(experiment_config)\n",
    "\n",
    "# 基准性能数据\n",
    "baseline_metrics = {\n",
    "    'accuracy': 0.75,\n",
    "    'precision': 0.73,\n",
    "    'recall': 0.78,\n",
    "    'f1_score': 0.75,\n",
    "    'auc_roc': 0.82\n",
    "}\n",
    "\n",
    "print(\"基准性能指标:\")\n",
    "for metric, value in baseline_metrics.items():\n",
    "    print(f\"- {metric}: {value:.3f}\")\n",
    "\n",
    "# 如果有模拟数据，显示对比\n",
    "if 'simulation_data' in locals():\n",
    "    print(\"\\n各方法性能对比:\")\n",
    "    \n",
    "    # 创建性能对比表\n",
    "    performance_df = pd.DataFrame(simulation_data).T\n",
    "    print(performance_df.round(3))\n",
    "    \n",
    "    # 计算相对于基准的改进\n",
    "    print(\"\\n相对于基准的改进:\")\n",
    "    for method in methods[1:]:  # 跳过基准方法\n",
    "        improvements = {}\n",
    "        for metric in metrics:\n",
    "            baseline_val = simulation_data['Baseline'][metric]\n",
    "            method_val = simulation_data[method][metric]\n",
    "            improvement = (method_val - baseline_val) / baseline_val * 100\n",
    "            improvements[metric] = improvement\n",
    "        \n",
    "        print(f\"\\n{method}:\")\n",
    "        for metric, improvement in improvements.items():\n",
    "            print(f\"  {metric}: {improvement:+.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 性能评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建性能评估可视化\n",
    "if 'simulation_data' in locals():\n",
    "    # 1. 雷达图显示各方法的综合性能\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # 雷达图\n",
    "    ax = axes[0, 0]\n",
    "    angles = np.linspace(0, 2 * np.pi, len(metrics), endpoint=False)\n",
    "    angles = np.concatenate((angles, [angles[0]]))\n",
    "    \n",
    "    for method in methods:\n",
    "        values = [simulation_data[method][metric] for metric in metrics]\n",
    "        values += [values[0]]\n",
    "        ax.plot(angles, values, 'o-', linewidth=2, label=method)\n",
    "        ax.fill(angles, values, alpha=0.1)\n",
    "    \n",
    "    ax.set_xticks(angles[:-1])\n",
    "    ax.set_xticklabels(metrics)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_title('各方法综合性能雷达图')\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "    \n",
    "    # 2. 条形图显示各指标对比\n",
    "    ax = axes[0, 1]\n",
    "    x = np.arange(len(metrics))\n",
    "    width = 0.2\n",
    "    \n",
    "    for i, method in enumerate(methods):\n",
    "        values = [simulation_data[method][metric] for metric in metrics]\n",
    "        ax.bar(x + i * width, values, width, label=method)\n",
    "    \n",
    "    ax.set_xlabel('指标')\n",
    "    ax.set_ylabel('性能值')\n",
    "    ax.set_title('各指标性能对比')\n",
    "    ax.set_xticks(x + width * 1.5)\n",
    "    ax.set_xticklabels(metrics, rotation=45)\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. 热力图显示性能矩阵\n",
    "    ax = axes[1, 0]\n",
    "    performance_matrix = np.array([[simulation_data[method][metric] for metric in metrics] for method in methods])\n",
    "    im = ax.imshow(performance_matrix, cmap='YlOrRd', aspect='auto')\n",
    "    \n",
    "    ax.set_xticks(range(len(metrics)))\n",
    "    ax.set_yticks(range(len(methods)))\n",
    "    ax.set_xticklabels(metrics, rotation=45)\n",
    "    ax.set_yticklabels(methods)\n",
    "    ax.set_title('性能热力图')\n",
    "    \n",
    "    # 添加数值标注\n",
    "    for i in range(len(methods)):\n",
    "        for j in range(len(metrics)):\n",
    "            text = ax.text(j, i, f'{performance_matrix[i, j]:.3f}',\n",
    "                         ha='center', va='center', color='black', fontsize=8)\n",
    "    \n",
    "    plt.colorbar(im, ax=ax)\n",
    "    \n",
    "    # 4. 改进幅度图\n",
    "    ax = axes[1, 1]\n",
    "    baseline_values = [simulation_data['Baseline'][metric] for metric in metrics]\n",
    "    best_values = [max(simulation_data[method][metric] for method in methods) for metric in metrics]\n",
    "    improvements = [(best - baseline) / baseline * 100 for best, baseline in zip(best_values, baseline_values)]\n",
    "    \n",
    "    bars = ax.bar(metrics, improvements, color='skyblue', alpha=0.7)\n",
    "    ax.set_ylabel('改进幅度 (%)')\n",
    "    ax.set_title('相对基准的最大改进幅度')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 添加数值标注\n",
    "    for bar, improvement in zip(bars, improvements):\n",
    "        height = bar.get_height()\n",
    "        ax.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "               f'{improvement:.1f}%', ha='center', va='bottom')\n",
    "    \n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 对比分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计显著性测试\n",
    "from scipy import stats\n",
    "\n",
    "if 'simulation_data' in locals():\n",
    "    print(\"统计显著性分析:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # 生成模拟的多次实验数据\n",
    "    n_experiments = 30\n",
    "    experiment_data = {}\n",
    "    \n",
    "    for method in methods:\n",
    "        experiment_data[method] = {}\n",
    "        for metric in metrics:\n",
    "            # 基于原始值生成正态分布的实验数据\n",
    "            mean_val = simulation_data[method][metric]\n",
    "            std_val = 0.02  # 2%的标准差\n",
    "            experiment_data[method][metric] = np.random.normal(mean_val, std_val, n_experiments)\n",
    "    \n",
    "    # 进行t检验\n",
    "    baseline_method = 'Baseline'\n",
    "    \n",
    "    for method in methods[1:]:\n",
    "        print(f\"\\n{method} vs {baseline_method}:\")\n",
    "        for metric in metrics:\n",
    "            baseline_scores = experiment_data[baseline_method][metric]\n",
    "            method_scores = experiment_data[method][metric]\n",
    "            \n",
    "            # 进行配对t检验\n",
    "            t_stat, p_value = stats.ttest_rel(method_scores, baseline_scores)\n",
    "            \n",
    "            # 计算效应大小 (Cohen's d)\n",
    "            pooled_std = np.sqrt((np.var(method_scores) + np.var(baseline_scores)) / 2)\n",
    "            cohens_d = (np.mean(method_scores) - np.mean(baseline_scores)) / pooled_std\n",
    "            \n",
    "            significance = \"***\" if p_value < 0.001 else \"**\" if p_value < 0.01 else \"*\" if p_value < 0.05 else \"ns\"\n",
    "            \n",
    "            print(f\"  {metric}: t={t_stat:.3f}, p={p_value:.4f} {significance}, d={cohens_d:.3f}\")\n",
    "    \n",
    "    # 创建箱线图显示分布\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, metric in enumerate(metrics):\n",
    "        ax = axes[i]\n",
    "        \n",
    "        data_to_plot = [experiment_data[method][metric] for method in methods]\n",
    "        box_plot = ax.boxplot(data_to_plot, labels=methods, patch_artist=True)\n",
    "        \n",
    "        # 设置颜色\n",
    "        colors = ['lightblue', 'lightgreen', 'lightcoral', 'lightyellow']\n",
    "        for patch, color in zip(box_plot['boxes'], colors):\n",
    "            patch.set_facecolor(color)\n",
    "        \n",
    "        ax.set_title(f'{metric.upper()} 分布')\n",
    "        ax.set_ylabel('性能值')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # 旋转x轴标签\n",
    "        plt.setp(ax.get_xticklabels(), rotation=45)\n",
    "    \n",
    "    # 隐藏多余的子图\n",
    "    if len(metrics) < len(axes):\n",
    "        axes[-1].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 错误分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 模拟错误分析数据\n",
    "np.random.seed(42)\n",
    "\n",
    "# 生成模拟的预测结果\n",
    "n_samples = 1000\n",
    "y_true = np.random.binomial(1, 0.3, n_samples)  # 30%的正样本\n",
    "\n",
    "# 不同方法的预测结果\n",
    "predictions = {}\n",
    "for method in methods:\n",
    "    # 基于方法性能生成预测\n",
    "    accuracy = simulation_data[method]['accuracy']\n",
    "    # 生成预测概率\n",
    "    pred_proba = np.random.beta(2, 2, n_samples)\n",
    "    # 调整预测概率以匹配准确率\n",
    "    pred_proba = pred_proba * accuracy + np.random.normal(0, 0.1, n_samples)\n",
    "    pred_proba = np.clip(pred_proba, 0, 1)\n",
    "    \n",
    "    # 生成二分类预测\n",
    "    y_pred = (pred_proba > 0.5).astype(int)\n",
    "    \n",
    "    predictions[method] = {\n",
    "        'y_pred': y_pred,\n",
    "        'y_proba': pred_proba\n",
    "    }\n",
    "\n",
    "# 错误分析\n",
    "print(\"错误分析报告:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for method in methods:\n",
    "    y_pred = predictions[method]['y_pred']\n",
    "    \n",
    "    # 计算混淆矩阵\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    \n",
    "    # 计算错误类型\n",
    "    false_positive_rate = fp / (fp + tn)\n",
    "    false_negative_rate = fn / (fn + tp)\n",
    "    \n",
    "    print(f\"\\n{method}:\")\n",
    "    print(f\"  假阳性率 (FPR): {false_positive_rate:.3f}\")\n",
    "    print(f\"  假阴性率 (FNR): {false_negative_rate:.3f}\")\n",
    "    print(f\"  假阳性数量: {fp}\")\n",
    "    print(f\"  假阴性数量: {fn}\")\n",
    "\n",
    "# 可视化混淆矩阵\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, method in enumerate(methods):\n",
    "    ax = axes[i]\n",
    "    y_pred = predictions[method]['y_pred']\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    # 绘制混淆矩阵热力图\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
    "    ax.set_title(f'{method} - 混淆矩阵')\n",
    "    ax.set_xlabel('预测标签')\n",
    "    ax.set_ylabel('真实标签')\n",
    "    ax.set_xticklabels(['负类', '正类'])\n",
    "    ax.set_yticklabels(['负类', '正类'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# ROC曲线对比\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "\n",
    "for method in methods:\n",
    "    y_proba = predictions[method]['y_proba']\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_proba)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.plot(fpr, tpr, linewidth=2, label=f'{method} (AUC = {roc_auc:.3f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', linewidth=1, label='随机分类器')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('假阳性率 (FPR)')\n",
    "plt.ylabel('真阳性率 (TPR)')\n",
    "plt.title('ROC曲线对比')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 参数敏感性分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参数敏感性分析\n",
    "print(\"参数敏感性分析:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 模拟不同参数设置下的性能\n",
    "parameters = {\n",
    "    'similarity_threshold': np.arange(0.7, 0.95, 0.05),\n",
    "    'num_variants': range(5, 21, 5),\n",
    "    'detection_threshold': np.arange(0.3, 0.8, 0.1),\n",
    "    'ensemble_weights': [(0.2, 0.3, 0.5), (0.3, 0.3, 0.4), (0.4, 0.3, 0.3), (0.5, 0.25, 0.25)]\n",
    "}\n",
    "\n",
    "# 为每个参数生成敏感性数据\n",
    "sensitivity_results = {}\n",
    "\n",
    "for param_name, param_values in parameters.items():\n",
    "    if param_name == 'ensemble_weights':\n",
    "        continue  # 跳过复杂参数\n",
    "    \n",
    "    performance_values = []\n",
    "    \n",
    "    for param_val in param_values:\n",
    "        # 模拟参数对性能的影响\n",
    "        if param_name == 'similarity_threshold':\n",
    "            # 相似度阈值：过高或过低都不好\n",
    "            optimal = 0.85\n",
    "            performance = 0.8 - 0.3 * abs(param_val - optimal)\n",
    "        elif param_name == 'num_variants':\n",
    "            # 变体数量：更多通常更好，但有边际递减效应\n",
    "            performance = 0.7 + 0.02 * param_val - 0.0005 * param_val**2\n",
    "        elif param_name == 'detection_threshold':\n",
    "            # 检测阈值：需要平衡精确率和召回率\n",
    "            optimal = 0.5\n",
    "            performance = 0.75 - 0.2 * abs(param_val - optimal)\n",
    "        \n",
    "        # 添加噪声\n",
    "        performance += np.random.normal(0, 0.02)\n",
    "        performance = np.clip(performance, 0, 1)\n",
    "        performance_values.append(performance)\n",
    "    \n",
    "    sensitivity_results[param_name] = {\n",
    "        'values': list(param_values),\n",
    "        'performance': performance_values\n",
    "    }\n",
    "\n",
    "# 可视化参数敏感性\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "param_names = list(sensitivity_results.keys())\n",
    "param_labels = {\n",
    "    'similarity_threshold': '相似度阈值',\n",
    "    'num_variants': '变体数量',\n",
    "    'detection_threshold': '检测阈值'\n",
    "}\n",
    "\n",
    "for i, param_name in enumerate(param_names):\n",
    "    ax = axes[i]\n",
    "    \n",
    "    values = sensitivity_results[param_name]['values']\n",
    "    performance = sensitivity_results[param_name]['performance']\n",
    "    \n",
    "    ax.plot(values, performance, 'o-', linewidth=2, markersize=6)\n",
    "    ax.set_xlabel(param_labels[param_name])\n",
    "    ax.set_ylabel('F1分数')\n",
    "    ax.set_title(f'{param_labels[param_name]}敏感性分析')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 标记最优点\n",
    "    best_idx = np.argmax(performance)\n",
    "    best_val = values[best_idx]\n",
    "    best_perf = performance[best_idx]\n",
    "    \n",
    "    ax.scatter([best_val], [best_perf], color='red', s=100, zorder=5)\n",
    "    ax.annotate(f'最优: {best_val}', \n",
    "               xy=(best_val, best_perf), \n",
    "               xytext=(10, 10), \n",
    "               textcoords='offset points',\n",
    "               bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.7),\n",
    "               arrowprops=dict(arrowstyle='->', connectionstyle='arc3,rad=0'))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 输出最优参数\n",
    "print(\"\\n推荐的最优参数设置:\")\n",
    "for param_name in param_names:\n",
    "    values = sensitivity_results[param_name]['values']\n",
    "    performance = sensitivity_results[param_name]['performance']\n",
    "    best_idx = np.argmax(performance)\n",
    "    best_val = values[best_idx]\n",
    "    best_perf = performance[best_idx]\n",
    "    \n",
    "    print(f\"- {param_labels[param_name]}: {best_val} (F1分数: {best_perf:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可视化报告"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成综合报告\n",
    "print(\"实验分析综合报告\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if 'simulation_data' in locals():\n",
    "    # 1. 最佳方法识别\n",
    "    method_scores = {}\n",
    "    for method in methods:\n",
    "        # 计算综合得分（所有指标的平均值）\n",
    "        avg_score = np.mean([simulation_data[method][metric] for metric in metrics])\n",
    "        method_scores[method] = avg_score\n",
    "    \n",
    "    best_method = max(method_scores, key=method_scores.get)\n",
    "    best_score = method_scores[best_method]\n",
    "    \n",
    "    print(f\"1. 最佳方法: {best_method}\")\n",
    "    print(f\"   综合得分: {best_score:.3f}\")\n",
    "    \n",
    "    # 2. 各方法排名\n",
    "    print(f\"\\n2. 方法排名:\")\n",
    "    sorted_methods = sorted(method_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "    for i, (method, score) in enumerate(sorted_methods, 1):\n",
    "        print(f\"   {i}. {method}: {score:.3f}\")\n",
    "    \n",
    "    # 3. 关键发现\n",
    "    print(f\"\\n3. 关键发现:\")\n",
    "    \n",
    "    # 找出改进最大的指标\n",
    "    max_improvements = {}\n",
    "    for metric in metrics:\n",
    "        baseline_val = simulation_data['Baseline'][metric]\n",
    "        best_val = max(simulation_data[method][metric] for method in methods)\n",
    "        improvement = (best_val - baseline_val) / baseline_val * 100\n",
    "        max_improvements[metric] = improvement\n",
    "    \n",
    "    best_improved_metric = max(max_improvements, key=max_improvements.get)\n",
    "    best_improvement = max_improvements[best_improved_metric]\n",
    "    \n",
    "    print(f\"   - 最大改进指标: {best_improved_metric} (+{best_improvement:.1f}%)\")\n",
    "    \n",
    "    # 找出最稳定的方法（方差最小）\n",
    "    method_variances = {}\n",
    "    for method in methods:\n",
    "        values = [simulation_data[method][metric] for metric in metrics]\n",
    "        variance = np.var(values)\n",
    "        method_variances[method] = variance\n",
    "    \n",
    "    most_stable = min(method_variances, key=method_variances.get)\n",
    "    print(f\"   - 最稳定方法: {most_stable} (方差: {method_variances[most_stable]:.4f})\")\n",
    "    \n",
    "    # 4. 建议\n",
    "    print(f\"\\n4. 建议:\")\n",
    "    print(f\"   - 推荐使用 {best_method} 方法以获得最佳整体性能\")\n",
    "    print(f\"   - 重点关注 {best_improved_metric} 指标的进一步优化\")\n",
    "    print(f\"   - 考虑 {most_stable} 方法的稳定性优势\")\n",
    "    \n",
    "    # 5. 参数建议\n",
    "    print(f\"\\n5. 参数建议:\")\n",
    "    for param_name in param_names:\n",
    "        values = sensitivity_results[param_name]['values']\n",
    "        performance = sensitivity_results[param_name]['performance']\n",
    "        best_idx = np.argmax(performance)\n",
    "        best_val = values[best_idx]\n",
    "        print(f\"   - {param_labels[param_name]}: {best_val}\")\n",
    "\n",
    "# 保存报告\n",
    "report_path = '../results/experiment_analysis_report.txt'\n",
    "os.makedirs(os.path.dirname(report_path), exist_ok=True)\n",
    "\n",
    "with open(report_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(\"多模态检测一致性实验分析报告\\n\")\n",
    "    f.write(\"=\" * 60 + \"\\n\\n\")\n",
    "    \n",
    "    if 'simulation_data' in locals():\n",
    "        f.write(f\"最佳方法: {best_method}\\n\")\n",
    "        f.write(f\"综合得分: {best_score:.3f}\\n\\n\")\n",
    "        \n",
    "        f.write(\"详细性能数据:\\n\")\n",
    "        for method in methods:\n",
    "            f.write(f\"\\n{method}:\\n\")\n",
    "            for metric in metrics:\n",
    "                value = simulation_data[method][metric]\n",
    "                f.write(f\"  {metric}: {value:.3f}\\n\")\n",
    "\n",
    "print(f\"\\n分析报告已保存到: {report_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 总结\n",
    "\n",
    "本notebook提供了全面的实验分析框架，包括：\n",
    "\n",
    "1. **性能评估**: 多维度评估各种方法的性能\n",
    "2. **统计分析**: 使用统计检验验证结果的显著性\n",
    "3. **错误分析**: 深入分析不同类型的错误\n",
    "4. **参数优化**: 分析关键参数对性能的影响\n",
    "5. **可视化报告**: 生成直观的图表和综合报告\n",
    "\n",
    "### 使用建议\n",
    "\n",
    "1. 将真实的实验数据替换模拟数据\n",
    "2. 根据具体需求调整评估指标\n",
    "3. 扩展参数敏感性分析的范围\n",
    "4. 添加更多的可视化类型\n",
    "5. 定期更新分析以跟踪改进进展"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}