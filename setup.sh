#!/bin/bash
# setup.sh - ç¯å¢ƒå®‰è£…è„šæœ¬
# å¤šæ¨¡æ€æ£€æµ‹ä¸€è‡´æ€§å®éªŒä»£ç ç¯å¢ƒé…ç½®
# Author: ZHANG XIN <zhang.xin@duke.edu>
# Duke University

set -e  # é‡åˆ°é”™è¯¯ç«‹å³é€€å‡º

# é¢œè‰²å®šä¹‰
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# æ—¥å¿—å‡½æ•°
log_info() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

# æ£€æŸ¥ç³»ç»Ÿè¦æ±‚
check_system_requirements() {
    log_info "æ£€æŸ¥ç³»ç»Ÿè¦æ±‚..."
    
    # æ£€æŸ¥æ“ä½œç³»ç»Ÿ
    if [[ "$OSTYPE" != "linux-gnu"* ]]; then
        log_error "æ­¤è„šæœ¬ä»…æ”¯æŒLinuxç³»ç»Ÿ"
        exit 1
    fi
    
    # æ£€æŸ¥Pythonç‰ˆæœ¬
    if ! command -v python3 &> /dev/null; then
        log_error "Python 3æœªå®‰è£…ï¼Œè¯·å…ˆå®‰è£…Python 3.8+"
        exit 1
    fi
    
    python_version=$(python3 -c "import sys; print(f'{sys.version_info.major}.{sys.version_info.minor}')")
    # ä½¿ç”¨Pythonè¿›è¡Œç‰ˆæœ¬æ¯”è¾ƒï¼Œé¿å…bcä¾èµ–
    version_check=$(python3 -c "import sys; print(1 if (sys.version_info.major, sys.version_info.minor) >= (3, 8) else 0)")
    if [[ $version_check -eq 0 ]]; then
        log_error "Pythonç‰ˆæœ¬è¿‡ä½ï¼Œéœ€è¦3.8+ï¼Œå½“å‰ç‰ˆæœ¬: $python_version"
        exit 1
    fi
    
    log_success "Pythonç‰ˆæœ¬æ£€æŸ¥é€šè¿‡: $python_version"
    
    # æ£€æŸ¥CUDA
    if command -v nvidia-smi &> /dev/null; then
        cuda_version=$(nvidia-smi | grep "CUDA Version" | awk '{print $9}')
        log_success "æ£€æµ‹åˆ°CUDAç‰ˆæœ¬: $cuda_version"
    else
        log_warning "æœªæ£€æµ‹åˆ°NVIDIA GPUï¼Œå°†ä½¿ç”¨CPUæ¨¡å¼"
    fi
    
    # æ£€æŸ¥å†…å­˜
    total_mem=$(free -g | awk '/^Mem:/{print $2}')
    if [[ $total_mem -lt 16 ]]; then
        log_warning "ç³»ç»Ÿå†…å­˜è¾ƒå°‘($total_mem GB)ï¼Œå»ºè®®è‡³å°‘32GBç”¨äºå¤§è§„æ¨¡å®éªŒ"
    else
        log_success "å†…å­˜æ£€æŸ¥é€šè¿‡: ${total_mem}GB"
    fi
    
    # æ£€æŸ¥ç£ç›˜ç©ºé—´
    available_space=$(df -BG . | awk 'NR==2 {print $4}' | sed 's/G//')
    if [[ $available_space -lt 100 ]]; then
        log_warning "ç£ç›˜ç©ºé—´ä¸è¶³($available_space GB)ï¼Œå»ºè®®è‡³å°‘2TBç”¨äºæ•°æ®é›†å’Œæ¨¡å‹"
    else
        log_success "ç£ç›˜ç©ºé—´æ£€æŸ¥é€šè¿‡: ${available_space}GBå¯ç”¨"
    fi
}

# æ£€æŸ¥å¹¶å®‰è£…conda
install_conda() {
    if command -v conda &> /dev/null; then
        log_success "Condaå·²å®‰è£…"
        return 0
    fi
    
    # æ£€æŸ¥æ˜¯å¦å·²æœ‰miniconda3ç›®å½•
    if [[ -d "$HOME/miniconda3" ]]; then
        log_info "æ£€æµ‹åˆ°ç°æœ‰Minicondaå®‰è£…ï¼Œåˆå§‹åŒ–ç¯å¢ƒ..."
        eval "$($HOME/miniconda3/bin/conda shell.bash hook)"
        conda init bash
        log_success "Minicondaç¯å¢ƒåˆå§‹åŒ–å®Œæˆ"
        return 0
    fi
    
    log_info "å®‰è£…Miniconda..."
    
    # ä¸‹è½½Miniconda
    wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O miniconda.sh
    
    # å®‰è£…Miniconda
    bash miniconda.sh -b -p $HOME/miniconda3
    
    # åˆå§‹åŒ–conda
    eval "$($HOME/miniconda3/bin/conda shell.bash hook)"
    conda init bash
    
    # æ¸…ç†å®‰è£…æ–‡ä»¶
    rm miniconda.sh
    
    log_success "Minicondaå®‰è£…å®Œæˆ"
}

# åˆ›å»ºcondaç¯å¢ƒ
create_conda_environment() {
    log_info "åˆ›å»ºcondaç¯å¢ƒ: mm_defense"
    
    # æ£€æŸ¥ç¯å¢ƒæ˜¯å¦å·²å­˜åœ¨
    if conda env list | grep -q "mm_defense"; then
        log_warning "ç¯å¢ƒmm_defenseå·²å­˜åœ¨ï¼Œæ˜¯å¦é‡æ–°åˆ›å»º? (y/n)"
        read -r response
        if [[ "$response" == "y" || "$response" == "Y" ]]; then
            conda env remove -n mm_defense -y
        else
            log_info "ä½¿ç”¨ç°æœ‰ç¯å¢ƒ"
            return 0
        fi
    fi
    
    # åˆ›å»ºæ–°ç¯å¢ƒ
    conda create -n mm_defense python=3.9 -y
    
    log_success "Condaç¯å¢ƒåˆ›å»ºå®Œæˆ"
}

# æ¿€æ´»condaç¯å¢ƒ
activate_environment() {
    log_info "æ¿€æ´»condaç¯å¢ƒ..."
    
    # åˆå§‹åŒ–condaï¼ˆå¦‚æœéœ€è¦ï¼‰
    if ! command -v conda &> /dev/null; then
        eval "$($HOME/miniconda3/bin/conda shell.bash hook)"
    fi
    
    # æ¿€æ´»ç¯å¢ƒ
    conda activate mm_defense
    
    log_success "ç¯å¢ƒæ¿€æ´»æˆåŠŸ"
}

# å®‰è£…PyTorchå’ŒCUDAæ”¯æŒ
install_pytorch() {
    log_info "å®‰è£…PyTorchå’Œç›¸å…³ä¾èµ–..."
    
    # æ£€æµ‹CUDAç‰ˆæœ¬å¹¶å®‰è£…å¯¹åº”çš„PyTorch
    if command -v nvidia-smi &> /dev/null; then
        cuda_version=$(nvidia-smi | grep "CUDA Version" | awk '{print $9}' | cut -d'.' -f1,2)
        
        if [[ "$cuda_version" == "11.8" ]] || [[ "$cuda_version" > "11.8" ]]; then
            log_info "å®‰è£…PyTorch with CUDA 11.8æ”¯æŒ"
            conda install pytorch torchvision torchaudio pytorch-cuda=11.8 -c pytorch -c nvidia -y
        elif [[ "$cuda_version" == "11.7" ]]; then
            log_info "å®‰è£…PyTorch with CUDA 11.7æ”¯æŒ"
            conda install pytorch torchvision torchaudio pytorch-cuda=11.7 -c pytorch -c nvidia -y
        else
            log_warning "CUDAç‰ˆæœ¬$cuda_versionå¯èƒ½ä¸å®Œå…¨å…¼å®¹ï¼Œå®‰è£…CPUç‰ˆæœ¬"
            conda install pytorch torchvision torchaudio cpuonly -c pytorch -y
        fi
    else
        log_info "å®‰è£…PyTorch CPUç‰ˆæœ¬"
        conda install pytorch torchvision torchaudio cpuonly -c pytorch -y
    fi
    
    log_success "PyTorchå®‰è£…å®Œæˆ"
}

# åˆ›å»ºrequirements.txtæ–‡ä»¶
create_requirements() {
    log_info "åˆ›å»ºrequirements.txtæ–‡ä»¶..."
    
    cat > requirements.txt << 'EOF'
# æ ¸å¿ƒæ·±åº¦å­¦ä¹ æ¡†æ¶
torch>=2.0.0
torchvision>=0.15.0
torchaudio>=2.0.0
transformers>=4.30.0
diffusers>=0.18.0
accelerate>=0.20.0

# CLIPå’Œå¤šæ¨¡æ€æ¨¡å‹
open-clip-torch>=2.20.0
clip-by-openai>=1.0
sentence-transformers>=2.2.0

# è®¡ç®—æœºè§†è§‰
opencv-python>=4.8.0
Pillow>=9.5.0
albumentations>=1.3.0
imagecorruptions>=1.1.2

# ç§‘å­¦è®¡ç®—
numpy>=1.24.0
scipy>=1.10.0
scikit-learn>=1.3.0
pandas>=2.0.0

# å¯è§†åŒ–
matplotlib>=3.7.0
seaborn>=0.12.0
plotly>=5.15.0
wandb>=0.15.0
tensorboard>=2.13.0

# æ•°æ®å¤„ç†
h5py>=3.9.0
pyarrow>=12.0.0
datasets>=2.13.0

# ç½‘ç»œå’ŒAPI
requests>=2.31.0
aiohttp>=3.8.0
fastapi>=0.100.0
uvicorn>=0.22.0

# é…ç½®å’Œå·¥å…·
PyYAML>=6.0
omegaconf>=2.3.0
hydra-core>=1.3.0
tqdm>=4.65.0
rich>=13.4.0

# æµ‹è¯•å’Œä»£ç è´¨é‡
pytest>=7.4.0
pytest-cov>=4.1.0
black>=23.7.0
flake8>=6.0.0
isort>=5.12.0
pre-commit>=3.3.0

# æ€§èƒ½ä¼˜åŒ–
numba>=0.57.0
faiss-cpu>=1.7.4
faiss-gpu>=1.7.4

# æ–‡æœ¬å¤„ç†
nltk>=3.8.0
spacy>=3.6.0
textblob>=0.17.0

# å…¶ä»–å·¥å…·
psutil>=5.9.0
gpustat>=1.1.0
colorama>=0.4.6
click>=8.1.0
EOF

    log_success "requirements.txtåˆ›å»ºå®Œæˆ"
}

# å®‰è£…Pythonä¾èµ–
install_python_dependencies() {
    log_info "å®‰è£…Pythonä¾èµ–åŒ…..."
    
    # å‡çº§pip
    pip install --upgrade pip setuptools wheel
    
    # å®‰è£…requirements.txtä¸­çš„ä¾èµ–
    pip install -r requirements.txt
    
    # å®‰è£…é¢å¤–çš„å¼€å‘å·¥å…·
    pip install jupyter jupyterlab ipywidgets
    
    # å®‰è£…FAISSï¼ˆæ ¹æ®CUDAæ”¯æŒé€‰æ‹©ç‰ˆæœ¬ï¼‰
    if command -v nvidia-smi &> /dev/null; then
        log_info "å®‰è£…FAISS GPUç‰ˆæœ¬"
        pip install faiss-gpu
    else
        log_info "å®‰è£…FAISS CPUç‰ˆæœ¬"
        pip install faiss-cpu
    fi
    
    log_success "Pythonä¾èµ–å®‰è£…å®Œæˆ"
}

# ä¸‹è½½å’Œé…ç½®æ¨¡å‹
setup_models() {
    log_info "é…ç½®é¢„è®­ç»ƒæ¨¡å‹..."
    
    # åˆ›å»ºæ¨¡å‹ç›®å½•
    mkdir -p models/clip
    mkdir -p models/stable_diffusion
    mkdir -p models/qwen
    
    # ä¸‹è½½CLIPæ¨¡å‹ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
    python3 -c "
import clip
import torch
print('ä¸‹è½½CLIP ViT-B/32æ¨¡å‹...')
model, preprocess = clip.load('ViT-B/32', device='cpu')
print('CLIPæ¨¡å‹ä¸‹è½½å®Œæˆ')
" || log_warning "CLIPæ¨¡å‹ä¸‹è½½å¤±è´¥ï¼Œå°†åœ¨é¦–æ¬¡ä½¿ç”¨æ—¶è‡ªåŠ¨ä¸‹è½½"
    
    # é…ç½®Hugging Faceç¼“å­˜ç›®å½•
    export HF_HOME="./models/huggingface"
    mkdir -p "$HF_HOME"
    
    log_success "æ¨¡å‹é…ç½®å®Œæˆ"
}

# åˆ›å»ºé¡¹ç›®ç›®å½•ç»“æ„
create_project_structure() {
    log_info "åˆ›å»ºé¡¹ç›®ç›®å½•ç»“æ„..."
    
    # åˆ›å»ºä¸»è¦ç›®å½•
    mkdir -p src/{attacks,models,utils,evaluation}
    mkdir -p configs/{attack_configs,defense_configs}
    mkdir -p data/{coco,flickr30k,processed}
    mkdir -p experiments
    mkdir -p tests
    mkdir -p notebooks
    mkdir -p results/{figures,tables,logs}
    mkdir -p cache/{sd_references,text_variants}
    mkdir -p scripts
    
    # åˆ›å»º__init__.pyæ–‡ä»¶
    touch src/__init__.py
    touch src/attacks/__init__.py
    touch src/models/__init__.py
    touch src/utils/__init__.py
    touch src/evaluation/__init__.py
    
    log_success "é¡¹ç›®ç›®å½•ç»“æ„åˆ›å»ºå®Œæˆ"
}

# åˆ›å»ºé…ç½®æ–‡ä»¶
create_config_files() {
    log_info "åˆ›å»ºé…ç½®æ–‡ä»¶..."
    
    # åˆ›å»ºé»˜è®¤é…ç½®æ–‡ä»¶
    cat > configs/default.yaml << 'EOF'
# é»˜è®¤é…ç½®æ–‡ä»¶
project:
  name: "multimodal_retrieval_defense"
  version: "1.0.0"
  author: "ZHANG XIN"
  email: "zhang.xin@duke.edu"

# æ¨¡å‹é…ç½®
models:
  clip:
    model_name: "ViT-B/32"
    device: "cuda"
    batch_size: 256
  
  stable_diffusion:
    model_name: "runwayml/stable-diffusion-v1-5"
    device: "cuda"
    fp16: true
    guidance_scale: 7.5
    num_inference_steps: 20
  
  qwen:
    model_name: "Qwen/Qwen-7B-Chat"
    api_key: null  # è®¾ç½®APIå¯†é’¥
    temperature: 0.7
    max_tokens: 512

# æ•°æ®é…ç½®
data:
  datasets:
    - name: "coco"
      path: "data/coco"
      split: "test"
    - name: "flickr30k"
      path: "data/flickr30k"
      split: "test"
  
  preprocessing:
    image_size: [224, 224]
    normalize: true
    augmentation: false

# é˜²å¾¡é…ç½®
defense:
  text_variants:
    num_variants: 10
    similarity_threshold: 0.85
    max_retries: 3
  
  retrieval:
    top_k: 20
    batch_size: 256
    similarity_metric: "cosine"
  
  sd_generation:
    images_per_variant: 3
    batch_size: 4
    enable_cache: true
    cache_dir: "cache/sd_references"
  
  detection:
    aggregation_method: "mean"
    threshold_method: "statistical"
    statistical_alpha: 1.5
    min_reference_size: 5

# æ”»å‡»é…ç½®
attacks:
  hubness:
    epsilon: 0.031372549  # 8/255
    alpha: 0.007843137    # 2/255
    iterations: 10
    lambda_balance: 0.3
    target_query_size: 100
  
  pgd:
    epsilon: 0.031372549
    alpha: 0.007843137
    iterations: 10
    random_start: true
  
  text:
    max_replace_ratio: 0.2
    alpha: 0.05
    iterations: 30

# å®éªŒé…ç½®
experiment:
  random_seeds: [42, 123, 456, 789, 999]
  num_runs: 5
  batch_size: 32
  save_intermediate: false
  
  evaluation:
    metrics: ["recall@1", "recall@5", "recall@10", "map", "auc"]
    top_k_values: [1, 5, 10, 20]

# æ—¥å¿—é…ç½®
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  file: "results/logs/experiment.log"
  console: true

# æ€§èƒ½é…ç½®
performance:
  num_workers: 4
  pin_memory: true
  persistent_workers: true
  enable_amp: true  # è‡ªåŠ¨æ··åˆç²¾åº¦
  compile_model: false  # PyTorch 2.0ç¼–è¯‘
EOF

    log_success "é…ç½®æ–‡ä»¶åˆ›å»ºå®Œæˆ"
}

# åˆ›å»ºç¯å¢ƒå˜é‡æ–‡ä»¶
create_env_file() {
    log_info "åˆ›å»ºç¯å¢ƒå˜é‡æ–‡ä»¶..."
    
    cat > .env << 'EOF'
# ç¯å¢ƒå˜é‡é…ç½®

# é¡¹ç›®è·¯å¾„
PROJECT_ROOT=/home/cw/zhangxin_workspace/å¤šæ¨¡æ€æ£€æµ‹ä¸€è‡´æ€§å®éªŒä»£ç 

# æ•°æ®è·¯å¾„
DATA_ROOT=${PROJECT_ROOT}/data
CACHE_ROOT=${PROJECT_ROOT}/cache
RESULTS_ROOT=${PROJECT_ROOT}/results

# æ¨¡å‹é…ç½®
HF_HOME=${PROJECT_ROOT}/models/huggingface
TORCH_HOME=${PROJECT_ROOT}/models/torch
CLIP_CACHE=${PROJECT_ROOT}/models/clip

# CUDAé…ç½®
CUDA_VISIBLE_DEVICES=0,1,2,3,4,5  # æ ¹æ®å®é™…GPUæ•°é‡è°ƒæ•´
CUDA_LAUNCH_BLOCKING=1

# æ€§èƒ½ä¼˜åŒ–
OMP_NUM_THREADS=8
MKL_NUM_THREADS=8
NUMBA_CACHE_DIR=${PROJECT_ROOT}/cache/numba

# APIé…ç½®ï¼ˆéœ€è¦ç”¨æˆ·å¡«å†™ï¼‰
QWEN_API_KEY=your_qwen_api_key_here
OPENAI_API_KEY=your_openai_api_key_here
HUGGINGFACE_TOKEN=your_huggingface_token_here

# æ—¥å¿—é…ç½®
LOG_LEVEL=INFO
WANDB_PROJECT=multimodal_retrieval_defense
WANDB_ENTITY=your_wandb_entity_here
EOF

    log_success "ç¯å¢ƒå˜é‡æ–‡ä»¶åˆ›å»ºå®Œæˆ"
}

# å®‰è£…é¡¹ç›®åŒ…
install_project_package() {
    log_info "å®‰è£…é¡¹ç›®åŒ…..."
    
    # åˆ›å»ºsetup.pyæ–‡ä»¶
    cat > setup.py << 'EOF'
from setuptools import setup, find_packages

with open("README.md", "r", encoding="utf-8") as fh:
    long_description = fh.read()

with open("requirements.txt", "r", encoding="utf-8") as fh:
    requirements = [line.strip() for line in fh if line.strip() and not line.startswith("#")]

setup(
    name="multimodal-retrieval-defense",
    version="1.0.0",
    author="ZHANG XIN",
    author_email="zhang.xin@duke.edu",
    description="Multi-Modal Retrieval Defense via Text Variant Consistency Detection",
    long_description=long_description,
    long_description_content_type="text/markdown",
    url="https://github.com/zhangxin-duke/multimodal-retrieval-defense",
    packages=find_packages(),
    classifiers=[
        "Development Status :: 4 - Beta",
        "Intended Audience :: Science/Research",
        "License :: OSI Approved :: MIT License",
        "Operating System :: POSIX :: Linux",
        "Programming Language :: Python :: 3",
        "Programming Language :: Python :: 3.8",
        "Programming Language :: Python :: 3.9",
        "Programming Language :: Python :: 3.10",
        "Topic :: Scientific/Engineering :: Artificial Intelligence",
    ],
    python_requires=">=3.8",
    install_requires=requirements,
    extras_require={
        "dev": [
            "pytest>=7.4.0",
            "pytest-cov>=4.1.0",
            "black>=23.7.0",
            "flake8>=6.0.0",
            "isort>=5.12.0",
            "pre-commit>=3.3.0",
        ],
        "notebooks": [
            "jupyter>=1.0.0",
            "jupyterlab>=4.0.0",
            "ipywidgets>=8.0.0",
        ],
    },
    entry_points={
        "console_scripts": [
            "mm-defense=src.cli:main",
        ],
    },
)
EOF

    # ä»¥å¼€å‘æ¨¡å¼å®‰è£…é¡¹ç›®
    pip install -e .
    
    log_success "é¡¹ç›®åŒ…å®‰è£…å®Œæˆ"
}

# éªŒè¯å®‰è£…
verify_installation() {
    log_info "éªŒè¯å®‰è£…..."
    
    # æµ‹è¯•Pythonå¯¼å…¥
    python3 -c "
import torch
import torchvision
import transformers
import diffusers
import clip
import numpy as np
import matplotlib.pyplot as plt
print('æ‰€æœ‰æ ¸å¿ƒä¾èµ–å¯¼å…¥æˆåŠŸ')
" || {
        log_error "ä¾èµ–å¯¼å…¥å¤±è´¥"
        exit 1
    }
    
    # æµ‹è¯•CUDAï¼ˆå¦‚æœå¯ç”¨ï¼‰
    if command -v nvidia-smi &> /dev/null; then
        python3 -c "
import torch
print(f'CUDAå¯ç”¨: {torch.cuda.is_available()}')
if torch.cuda.is_available():
    print(f'CUDAè®¾å¤‡æ•°é‡: {torch.cuda.device_count()}')
    print(f'å½“å‰è®¾å¤‡: {torch.cuda.current_device()}')
    print(f'è®¾å¤‡åç§°: {torch.cuda.get_device_name()}')
" || log_warning "CUDAæµ‹è¯•å¤±è´¥"
    fi
    
    # æ£€æŸ¥é¡¹ç›®ç»“æ„
    if [[ -d "src" && -d "configs" && -d "data" ]]; then
        log_success "é¡¹ç›®ç»“æ„éªŒè¯é€šè¿‡"
    else
        log_error "é¡¹ç›®ç»“æ„ä¸å®Œæ•´"
        exit 1
    fi
    
    log_success "å®‰è£…éªŒè¯å®Œæˆ"
}

# åˆ›å»ºå¿«é€Ÿæµ‹è¯•è„šæœ¬
create_test_script() {
    log_info "åˆ›å»ºå¿«é€Ÿæµ‹è¯•è„šæœ¬..."
    
    cat > test_installation.py << 'EOF'
#!/usr/bin/env python3
"""
å®‰è£…éªŒè¯æµ‹è¯•è„šæœ¬
"""

import sys
import torch
import clip
import numpy as np
from pathlib import Path

def test_basic_imports():
    """æµ‹è¯•åŸºç¡€å¯¼å…¥"""
    try:
        import torch
        import torchvision
        import transformers
        import diffusers
        import clip
        import numpy as np
        import matplotlib.pyplot as plt
        import sklearn
        import pandas as pd
        print("âœ“ æ‰€æœ‰åŸºç¡€ä¾èµ–å¯¼å…¥æˆåŠŸ")
        return True
    except ImportError as e:
        print(f"âœ— å¯¼å…¥å¤±è´¥: {e}")
        return False

def test_cuda_availability():
    """æµ‹è¯•CUDAå¯ç”¨æ€§"""
    if torch.cuda.is_available():
        print(f"âœ“ CUDAå¯ç”¨ï¼Œè®¾å¤‡æ•°é‡: {torch.cuda.device_count()}")
        for i in range(torch.cuda.device_count()):
            print(f"  è®¾å¤‡ {i}: {torch.cuda.get_device_name(i)}")
        return True
    else:
        print("âš  CUDAä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUæ¨¡å¼")
        return False

def test_clip_model():
    """æµ‹è¯•CLIPæ¨¡å‹åŠ è½½"""
    try:
        device = "cuda" if torch.cuda.is_available() else "cpu"
        model, preprocess = clip.load("ViT-B/32", device=device)
        print(f"âœ“ CLIPæ¨¡å‹åŠ è½½æˆåŠŸï¼Œè®¾å¤‡: {device}")
        return True
    except Exception as e:
        print(f"âœ— CLIPæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return False

def test_project_structure():
    """æµ‹è¯•é¡¹ç›®ç»“æ„"""
    required_dirs = [
        "src", "configs", "data", "experiments", 
        "tests", "notebooks", "results", "cache"
    ]
    
    missing_dirs = []
    for dir_name in required_dirs:
        if not Path(dir_name).exists():
            missing_dirs.append(dir_name)
    
    if missing_dirs:
        print(f"âœ— ç¼ºå°‘ç›®å½•: {missing_dirs}")
        return False
    else:
        print("âœ“ é¡¹ç›®ç»“æ„å®Œæ•´")
        return True

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("=" * 50)
    print("å¤šæ¨¡æ€æ£€æµ‹ä¸€è‡´æ€§å®éªŒä»£ç  - å®‰è£…éªŒè¯")
    print("=" * 50)
    
    tests = [
        ("åŸºç¡€ä¾èµ–å¯¼å…¥", test_basic_imports),
        ("CUDAå¯ç”¨æ€§", test_cuda_availability),
        ("CLIPæ¨¡å‹åŠ è½½", test_clip_model),
        ("é¡¹ç›®ç»“æ„", test_project_structure),
    ]
    
    passed = 0
    total = len(tests)
    
    for test_name, test_func in tests:
        print(f"\næµ‹è¯•: {test_name}")
        if test_func():
            passed += 1
    
    print("\n" + "=" * 50)
    print(f"æµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç¯å¢ƒé…ç½®æˆåŠŸ")
        return 0
    else:
        print("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥å®‰è£…")
        return 1

if __name__ == "__main__":
    sys.exit(main())
EOF

    chmod +x test_installation.py
    
    log_success "æµ‹è¯•è„šæœ¬åˆ›å»ºå®Œæˆ"
}

# æ‰“å°ä½¿ç”¨è¯´æ˜
print_usage_instructions() {
    log_info "å®‰è£…å®Œæˆï¼ä½¿ç”¨è¯´æ˜ï¼š"
    
    echo -e ""
echo -e "${GREEN}=== ç¯å¢ƒæ¿€æ´» ===${NC}"
echo -e "conda activate mm_defense"
echo -e ""
echo -e "${GREEN}=== å¿«é€Ÿæµ‹è¯• ===${NC}"
echo -e "python test_installation.py"
echo -e ""
echo -e "${GREEN}=== é…ç½®APIå¯†é’¥ ===${NC}"
echo -e "ç¼–è¾‘ .env æ–‡ä»¶ï¼Œè®¾ç½®ä»¥ä¸‹APIå¯†é’¥ï¼š"
echo -e "- QWEN_API_KEY: Qwenå¤§æ¨¡å‹APIå¯†é’¥"
echo -e "- OPENAI_API_KEY: OpenAI APIå¯†é’¥ï¼ˆå¯é€‰ï¼‰"
echo -e "- HUGGINGFACE_TOKEN: Hugging Faceè®¿é—®ä»¤ç‰Œ"
echo -e ""
echo -e "${GREEN}=== ä¸‹è½½æ•°æ®é›† ===${NC}"
echo -e "python scripts/download_coco.py"
echo -e "python scripts/download_flickr30k.py"
echo -e ""
echo -e "${GREEN}=== è¿è¡Œå®éªŒ ===${NC}"
echo -e "python experiments/run_experiments.py --config configs/default.yaml"
echo -e ""
echo -e "${GREEN}=== å¼€å‘æ¨¡å¼ ===${NC}"
echo -e "jupyter lab  # å¯åŠ¨Jupyter Lab"
echo -e "pytest tests/  # è¿è¡Œå•å…ƒæµ‹è¯•"
echo -e ""
echo -e "${YELLOW}æ³¨æ„äº‹é¡¹ï¼š${NC}"
echo -e "1. é¦–æ¬¡è¿è¡Œä¼šè‡ªåŠ¨ä¸‹è½½é¢„è®­ç»ƒæ¨¡å‹ï¼Œéœ€è¦ç½‘ç»œè¿æ¥"
echo -e "2. å¤§è§„æ¨¡å®éªŒéœ€è¦å……è¶³çš„GPUå†…å­˜å’Œå­˜å‚¨ç©ºé—´"
echo -e "3. å»ºè®®åœ¨è¿è¡Œå®éªŒå‰å…ˆæ‰§è¡Œå¿«é€Ÿæµ‹è¯•éªŒè¯ç¯å¢ƒ"
echo -e ""
}

# ä¸»å‡½æ•°
main() {
    echo -e "${BLUE}"
    echo "================================================"
    echo "  å¤šæ¨¡æ€æ£€æµ‹ä¸€è‡´æ€§å®éªŒä»£ç  - ç¯å¢ƒå®‰è£…è„šæœ¬"
    echo "  Author: ZHANG XIN <zhang.xin@duke.edu>"
    echo "  Duke University"
    echo "================================================"
    echo -e "${NC}"
    
    # æ‰§è¡Œå®‰è£…æ­¥éª¤
    check_system_requirements
    install_conda
    create_conda_environment
    
    # æ¿€æ´»ç¯å¢ƒå¹¶ç»§ç»­å®‰è£…
    source $HOME/miniconda3/etc/profile.d/conda.sh
    conda activate mm_defense
    
    install_pytorch
    create_requirements
    install_python_dependencies
    setup_models
    create_project_structure
    create_config_files
    create_env_file
    install_project_package
    create_test_script
    verify_installation
    
    log_success "ç¯å¢ƒå®‰è£…å®Œæˆï¼"
    print_usage_instructions
}

# é”™è¯¯å¤„ç†
trap 'log_error "å®‰è£…è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯ï¼Œè¯·æ£€æŸ¥æ—¥å¿—"' ERR

# è¿è¡Œä¸»å‡½æ•°
if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
    main "$@"
fi