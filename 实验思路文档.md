# 基于文本变体一致性检测的多模态检索防御方法实验设计

## 1. 背景与目标

### 1.1 攻击背景
基于《Adversarial Hubness in Multi-Modal Retrieval》论文 <mcreference link="https://github.com/tingwei-zhang/adv_hub" index="1">1</mcreference> <mcreference link="https://arxiv.org/html/2412.14113v2" index="2">2</mcreference>，该攻击方法利用高维向量空间中的hubness现象，将任意图像或音频输入转化为对抗性hub，使其能够被大量不相关的查询检索到。

### 1.2 防御策略核心思想
通过文本变体生成和一致性检测来识别对抗性查询：
- 对原始查询生成多个语义相似的文本变体
- 利用Stable Diffusion生成参考图像向量
- 通过一致性分析检测异常检索结果

## 2. 详细实验流程

### 2.1 数据集准备

#### 2.1.1 数据集选择
- **COCO-1k**: 1000个测试查询，用于快速验证
- **Flickr30k**: 完整数据集，用于全面评估
- **Gallery规模**: 支持10k、100k、1M规模测试

#### 2.1.2 数据预处理
```python
# 图像预处理（遵循CLIP ViT-B/32标准）
image_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(
        mean=[0.481, 0.457, 0.408],
        std=[0.268, 0.261, 0.275]
    )
])

# 文本预处理
text_tokenizer = clip.tokenize  # CLIP-BPE, max_length=77
```

### 2.2 攻击方法复现

#### 2.2.1 Hubness攻击参数（严格遵循论文）
```python
ATTACK_CONFIG = {
    'random_seed': 42,
    'model': 'CLIP ViT-B/32',
    'hubness_stats': {
        'top_k': 10,
        'hub_count': 256,
        'softmax_temperature': 0.07
    },
    'image_attack': {
        'epsilon': 8/255,
        'alpha': 2/255,  # ε/4
        'iterations': 10,
        'lambda_balance': 0.3,
        'momentum': 1.0,  # for MI-FGSM
        'target_query_size': 100
    },
    'text_attack': {
        'max_replace_ratio': 0.2,
        'alpha_txt': 0.05,
        'iterations_txt': 30,
        'candidate_vocab_size': 50,
        'lambda_balance': 0.3
    },
    'evaluation': {
        'batch_size': 256,
        'metrics': ['Recall@1', 'Recall@5', 'Recall@10', 'mAP'],
        'success_criterion': 'mAP从~63%降至≤10%'
    }
}
```

### 2.3 防御方法实现流程

#### 2.3.1 文本变体生成（步骤A）
```python
def generate_text_variants(query: str, N: int, sim_thresh: float = 0.85) -> List[str]:
    """
    使用Qwen大模型生成文本变体
    
    Args:
        query: 原始查询文本
        N: 生成变体数量
        sim_thresh: 相似度过滤阈值
    
    Returns:
        过滤后的文本变体列表
    """
    # 1. 调用Qwen API生成N个变体
    # 2. 计算CLIP文本嵌入相似度
    # 3. 过滤相似度过低的变体
    # 4. 去重处理
    pass
```

#### 2.3.2 检索收集（步骤B）
```python
def retrieve_topk_images(text_variants: List[str], k: int) -> np.ndarray:
    """
    对每个文本变体执行Top-K检索
    
    Args:
        text_variants: 文本变体列表
        k: Top-K参数
    
    Returns:
        检索到的图像向量矩阵 (total_retrieved, embedding_dim)
    """
    # 1. 批量编码文本变体
    # 2. 与gallery进行相似度计算
    # 3. 收集Top-K图像向量
    pass
```

#### 2.3.3 SD参考向量生成（步骤C）
```python
def generate_sd_references(text_variants: List[str], M: int) -> np.ndarray:
    """
    使用Stable Diffusion生成参考向量
    
    Args:
        text_variants: 文本变体列表
        M: 每个变体生成的图像数量
    
    Returns:
        平均后的参考向量矩阵 (len(text_variants), embedding_dim)
    """
    # 1. 批量调用SD生成图像
    # 2. CLIP编码生成的图像
    # 3. 对每个变体的M张图像求平均
    pass
```

#### 2.3.4 参考向量库构建（步骤D）
```python
def build_reference_bank(retrieved_vectors: np.ndarray, 
                        sd_vectors: np.ndarray) -> np.ndarray:
    """
    构建归一化的参考向量库
    
    Args:
        retrieved_vectors: 检索到的图像向量
        sd_vectors: SD生成的参考向量
    
    Returns:
        L2归一化的参考向量库
    """
    # 1. 合并两类向量
    # 2. L2归一化处理
    # 3. 去重（可选）
    pass
```

#### 2.3.5 一致性检测（步骤E-F）
```python
def detect_adversarial_candidate(candidate_vector: np.ndarray,
                                reference_bank: np.ndarray,
                                threshold: float) -> Tuple[bool, float]:
    """
    检测候选图像是否为对抗样本
    
    Args:
        candidate_vector: 候选图像向量
        reference_bank: 参考向量库
        threshold: 检测阈值
    
    Returns:
        (is_adversarial, consistency_score)
    """
    # 1. 计算与参考向量的相似度
    # 2. 聚合相似度分数（平均/最大值）
    # 3. 与阈值比较
    pass
```

### 2.4 阈值确定策略

#### 2.4.1 统计方法
```python
def compute_threshold(clean_scores: np.ndarray, method: str = 'statistical') -> float:
    """
    基于验证集计算检测阈值
    
    Args:
        clean_scores: 干净样本的一致性分数
        method: 阈值计算方法
    
    Returns:
        检测阈值
    """
    if method == 'statistical':
        # θ = μ_clean - 1.5σ_clean
        return np.mean(clean_scores) - 1.5 * np.std(clean_scores)
    elif method == 'percentile':
        # θ = P5_clean (第5百分位数)
        return np.percentile(clean_scores, 5)
    else:
        raise ValueError(f"Unknown method: {method}")
```

## 3. 超参数设计

### 3.1 核心超参数
```python
HYPERPARAMETERS = {
    'text_variants': {
        'N': [5, 10, 20],  # 变体数量
        'similarity_threshold': [0.8, 0.85, 0.9]  # 相似度过滤
    },
    'retrieval': {
        'K_text': [10, 20, 50],  # Top-K检索
        'K_consistency': [5, 10, 20]  # 一致性检测Top-K
    },
    'sd_generation': {
        'M': [1, 3, 5],  # 每个变体生成图像数
        'batch_size': [4, 8, 16],  # SD批处理大小
        'guidance_scale': [7.5, 10.0, 12.5],  # SD引导强度
        'num_inference_steps': [20, 50]  # SD推理步数
    },
    'threshold': {
        'method': ['statistical', 'percentile'],
        'alpha': [1.0, 1.5, 2.0],  # 统计方法的标准差系数
        'percentile': [1, 5, 10]  # 百分位数方法的分位点
    }
}
```

### 3.2 数据集配置
```python
DATASET_CONFIG = {
    'validation_size': 1000,  # 阈值计算用
    'test_size': 1000,       # 最终评估用
    'gallery_sizes': [10000, 100000, 1000000],  # 不同规模测试
    'attack_types': ['hubness', 'pgd_image', 'textfooler'],
    'random_seeds': [42, 123, 456, 789, 999]  # 多次实验
}
```

## 4. 评估指标体系

### 4.1 检索性能恢复
```python
RETRIEVAL_METRICS = {
    'recall_at_k': [1, 5, 10],
    'mean_average_precision': True,
    'mean_reciprocal_rank': True,
    'ndcg_at_k': [5, 10]
}
```

### 4.2 攻击检测效果
```python
DETECTION_METRICS = {
    'tpr_fpr': True,  # 真阳性率/假阳性率
    'roc_auc': True,  # ROC曲线下面积
    'fpr_at_95_tpr': True,  # 95%TPR时的FPR
    'precision_recall_f1': True,  # 精确率/召回率/F1
    'equal_error_rate': True  # 等错误率
}
```

### 4.3 效率开销
```python
EFFICIENCY_METRICS = {
    'text_augment_time': True,  # 文本变体生成时间
    'sd_generation_time': True,  # SD图像生成时间
    'retrieval_time': True,     # 检索时间
    'detection_time': True,     # 检测时间
    'total_latency': True,      # 总延迟
    'gpu_memory_usage': True,   # GPU内存占用
    'cpu_usage': True          # CPU使用率
}
```

## 5. 实验设计矩阵

### 5.1 主要实验组合
```python
EXPERIMENT_MATRIX = [
    # 基线实验
    {'condition': 'clean', 'defense': False, 'attack': None},
    
    # 攻击实验
    {'condition': 'attack', 'defense': False, 'attack': 'hubness'},
    {'condition': 'attack', 'defense': False, 'attack': 'pgd_image'},
    {'condition': 'attack', 'defense': False, 'attack': 'textfooler'},
    
    # 防御实验
    {'condition': 'defense', 'defense': True, 'attack': 'hubness'},
    {'condition': 'defense', 'defense': True, 'attack': 'pgd_image'},
    {'condition': 'defense', 'defense': True, 'attack': 'textfooler'},
    
    # 自适应攻击
    {'condition': 'adaptive', 'defense': True, 'attack': 'adaptive_hubness'}
]

### 5.3 自适应攻击实现细节
```python
ADAPTIVE_ATTACK_CONFIG = {
    'adaptive_hubness': {
        'base_loss': 'hubness_loss',  # 原始hubness攻击损失
        'consistency_penalty': True,  # 加入一致性最大化项
        'beta_values': [0.5, 1.0, 2.0],  # 平衡系数
        'loss_formula': 'L = L_hub - β·consistency_score',
        'optimization': {
            'iterations': 20,  # 增加迭代次数
            'learning_rate': 0.01,
            'momentum': 0.9
        }
    },
    'white_box_assumption': {
        'known_components': ['text_variants', 'sd_generation', 'threshold'],
        'unknown_components': ['reference_bank_construction'],  # 部分信息隐藏
        'attack_strategy': 'maximize_consistency_while_maintain_hubness'
    }
}
```
```

### 5.2 消融实验
```python
ABLATION_STUDIES = {
    'text_variants_only': '仅使用文本变体，不使用SD生成',
    'sd_only': '仅使用SD生成，不使用检索向量',
    'different_aggregation': '不同相似度聚合方法（平均vs最大值）',
    'threshold_methods': '不同阈值计算方法对比',
    'variant_quality': '不同质量文本变体的影响'
}
```

## 6. 统计显著性验证

### 6.1 多次实验设计
```python
STATISTICAL_CONFIG = {
    'num_runs': 5,  # 独立实验次数
    'confidence_level': 0.95,  # 置信水平
    'significance_test': 't_test',  # 显著性检验方法
    'effect_size': 'cohen_d',  # 效应量计算
    'bootstrap_samples': 1000  # Bootstrap样本数
}
```

### 6.2 报告格式
```python
RESULT_FORMAT = {
    'mean_std': True,  # 均值±标准差
    'confidence_interval': True,  # 置信区间
    'p_value': True,  # p值
    'effect_size': True  # 效应量
}
```

### 6.3 数据分割与泄漏防护
```python
DATA_SPLIT_CONFIG = {
    'validation_clean': {
        'size': 1000,
        'purpose': 'threshold_selection',
        'isolation': 'strict_separation_from_test'
    },
    'test_clean': {
        'size': 1000,
        'purpose': 'final_evaluation',
        'no_hyperparameter_tuning': True
    },
    'split_strategy': {
        'random_seed': 42,
        'stratified': True,  # 保持类别平衡
        'temporal_split': False,  # 非时序数据
        'cross_validation': False  # 避免数据泄漏
    },
    'verification': {
        'overlap_check': True,  # 检查重叠
        'distribution_check': True,  # 分布一致性检查
        'leakage_detection': 'automated_script'  # 自动化泄漏检测
    }
}
```

## 7. 预期结果与成功标准

### 7.1 防御效果标准
- **检索性能恢复**: 防御后Recall@1从攻击时的≤10%恢复到≥40%
- **检测准确性**: AUC ≥ 0.90, FPR@95%TPR ≤ 5%
- **泛化能力**: 在不同攻击类型上保持一致的防御效果
- **效率要求**: 单次查询延迟增加 ≤ 2倍

### 7.2 论文贡献点
1. **新颖的防御思路**: 基于文本变体一致性的检测方法
2. **多模态参考构建**: 结合检索和生成的参考向量库
3. **全面的评估体系**: 涵盖多种攻击类型和评估指标
4. **实用性验证**: 在真实规模数据集上的有效性证明

## 8. 风险与挑战

### 8.1 技术挑战
- **文本变体质量**: Qwen生成的变体可能存在语义偏移
- **SD生成稳定性**: 生成图像的质量和一致性
- **计算开销**: 实时检测的效率要求
- **阈值敏感性**: 不同数据集上的阈值泛化

### 8.2 对策方案
- **变体质量控制**: 多轮过滤和人工验证
- **SD参数优化**: 针对检索任务的专门调优
- **并行加速**: GPU并行处理和缓存机制
- **自适应阈值**: 基于在线学习的动态调整

### 8.3 SD生成延迟优化策略
```python
SD_OPTIMIZATION_CONFIG = {
    'offline_caching': {
        'precompute_variants': True,  # 预计算常见查询的变体
        'cache_sd_references': True,  # 缓存SD生成的参考向量
        'cache_size_limit': '50GB',  # 缓存大小限制
        'cache_update_frequency': 'daily'  # 缓存更新频率
    },
    'online_strategy': {
        'fast_path': 'retrieval_reference_only',  # 快速路径：仅用检索参考
        'slow_path': 'full_sd_generation',  # 慢速路径：完整SD生成
        'fallback_threshold': 100,  # ms，超时则降级到快速路径
        'async_sd_generation': True  # 异步SD生成
    },
    'performance_optimization': {
        'fp16_inference': True,  # FP16推理
        'torch_compile': True,  # PyTorch编译优化
        'batch_processing': True,  # 批处理
        'gpu_memory_fraction': 0.8  # GPU内存使用比例
    }
}
```

### 8.4 阈值漂移与在线更新
```python
THRESHOLD_ADAPTATION_CONFIG = {
    'drift_detection': {
        'monitoring_window': 10000,  # 每10k新样本检查一次
        'drift_threshold': 0.1,  # 分布漂移阈值
        'statistical_test': 'ks_test'  # Kolmogorov-Smirnov检验
    },
    'online_update': {
        'clean_sample_size': 500,  # 重新采样的干净样本数
        'update_frequency': 'adaptive',  # 自适应更新频率
        'sliding_window': True,  # 滑动窗口估计
        'exponential_smoothing': 0.9  # 指数平滑系数
    },
    'threshold_formula': {
        'statistical': 'θ_new = α·θ_old + (1-α)·(μ_new - β·σ_new)',
        'percentile': 'θ_new = α·θ_old + (1-α)·P5_new',
        'alpha': 0.9,  # 历史权重
        'beta': 1.5   # 标准差系数
    }
}
```

## 9. 时间规划

### 9.1 实施阶段（预计8周）
- **Week 1-2**: 代码框架搭建和基础模块实现
- **Week 3-4**: 攻击方法复现和验证
- **Week 5-6**: 防御方法实现和调试
- **Week 7-8**: 全面实验和结果分析

### 9.2 论文撰写（预计4周）
- **Week 9-10**: 初稿撰写
- **Week 11-12**: 修改完善和投稿准备

## 10. 基线方法扩展

### 10.1 额外基线方法
```python
BASELINE_METHODS = {
    'distance_based_ood': {
        'mahalanobis_distance': {
            'description': '基于马氏距离的异常检测',
            'implementation': 'sklearn.covariance.EmpiricalCovariance',
            'hyperparameters': ['regularization']
        },
        'energy_score': {
            'description': '基于能量分数的OOD检测',
            'formula': 'E(x) = -log(∑exp(f_i(x)))',
            'temperature': [1.0, 2.0, 5.0]
        }
    },
    'existing_defenses': {
        'csls': {
            'description': 'Cross-domain Similarity Local Scaling',
            'k_neighbors': [5, 10, 20]
        },
        'spectral_regularization': {
            'description': 'Spectral Regularization',
            'lambda_reg': [0.1, 0.5, 1.0]
        }
    },
    'comparison_metrics': {
        'detection_performance': ['AUC', 'FPR@95TPR', 'AUROC'],
        'retrieval_recovery': ['Recall@K', 'mAP', 'MRR'],
        'computational_cost': ['inference_time', 'memory_usage']
    }
}
```

### 10.2 代码实现优化
```python
IMPLEMENTATION_OPTIMIZATIONS = {
    'precision_optimization': {
        'fp16_models': ['clip', 'stable_diffusion'],
        'mixed_precision': 'torch.cuda.amp.autocast',
        'memory_savings': '~50%'
    },
    'reproducibility': {
        'seed_components': [
            'torch.manual_seed',
            'numpy.random.seed', 
            'random.seed',
            'torch.cuda.manual_seed_all',
            'diffusers.utils.set_seed'
        ],
        'deterministic_algorithms': True,
        'benchmark_mode': False  # 确保可重复性
    },
    'logging_and_visualization': {
        'structured_logging': {
            'format': 'Clean | Attack | Defense',
            'metrics_per_row': ['Recall@1', 'Recall@5', 'mAP', 'AUC'],
            'export_format': ['csv', 'json', 'wandb']
        },
        'automated_plotting': {
            'roc_curves': 'matplotlib + seaborn',
            'recall_vs_epsilon': 'line_plot_with_error_bars',
            'latency_breakdown': 'stacked_bar_chart',
            'confusion_matrices': 'heatmap_visualization'
        }
    }
}
```

### 10.3 论文写作预埋
```python
PAPER_PREPARATION = {
    'table_templates': {
        'main_results': {
            'columns': ['Method', 'Clean', 'Attack', 'Defense', 'Recovery%'],
            'rows': ['Recall@1', 'Recall@5', 'mAP', 'AUC'],
            'format': 'mean±std (p-value)'
        },
        'ablation_study': {
            'components': ['Text Variants', 'SD Reference', 'Aggregation'],
            'metrics': ['AUC', 'FPR@95TPR', 'Latency']
        }
    },
    'figure_scripts': {
        'roc_comparison': 'scripts/plot_roc_curves.py',
        'recall_vs_attack_strength': 'scripts/plot_recall_epsilon.py',
        'latency_breakdown': 'scripts/plot_latency_analysis.py',
        'threshold_sensitivity': 'scripts/plot_threshold_analysis.py'
    },
    'automated_reporting': {
        'latex_table_generation': True,
        'figure_caption_templates': True,
        'statistical_significance_formatting': True
    }
}
```

## 11. 资源需求

### 10.1 硬件资源
- **GPU**: 6张RTX 4090充分利用
- **存储**: 至少2TB用于数据集和模型
- **内存**: 256GB以上用于大规模实验

### 10.2 软件依赖
- **深度学习框架**: PyTorch 2.0+
- **多模态模型**: CLIP, Stable Diffusion
- **大语言模型**: Qwen API
- **评估工具**: scikit-learn, matplotlib, wandb

---

*本文档将作为实验实施的指导性文件，具体实现过程中可能根据实际情况进行调整。*